knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(ISLR)
OJ
# train/test split
set.seed(0)
train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.train = OJ[train, ]
OJ.test = OJ[-train, ]
# construct initial tree
library(tree)
initial.tree = tree(Purchase ~ ., split = "gini", data = OJ.train)
# training accuracy
summary(initial.tree)
# testing accuracy
tree.predictions = predict(initial.tree, OJ.test, type = "class")
table(tree.predictions, OJ.test$Purchase)
(106 + 59)/nrow(OJ.test)
#####################################################
#####Example using the State Information Dataset#####
#####################################################
help(state.x77)
state.x77 #Investigating the state.x77 dataset.
states = as.data.frame(state.x77) #Forcing the state.x77 dataset to be a dataframe.
#Cleaning up the column names so that there are no spaces.
colnames(states)[4] = "Life.Exp"
colnames(states)[6] = "HS.Grad"
#Creating a population density variable.
states[,9] = (states$Population*1000)/states$Area
colnames(states)[9] = "Density"
#Basic numerical EDA for states dataset.
summary(states)
sapply(states, sd)
cor(states)
sapply(states, sd)
cor(states)
?cor
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
restaurants = read.table("https://s3.amazonaws.com/nycdsabt01/NYC_Restaurants.txt")
library(ggplot2)
library(ggplot2)
library(GGally)
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
ggpairs(restaurants[,2:6], aes(color = Location))
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
ggpairs(restaurants[,2:6], aes(color = Location))
colnames(restaurants)
head(restaurants)
model.saturated = lm(Price ~ Food + Decor + Service + Location, data = restaurants)
summary(model.saturated)
?vif
?vif()
vif(model.saturated)
library(car)
influencePlot(model.saturated)
vif(model.saturated)
?vif
model.service = lm(Price ~ Service, data = restaurants)
summary(model.service)
influencePlot(model.service)
summary(model.service)
model1 = lm(Price ~ Food + Decor, data = restaurants)
summary(model1)
plot(model1)
influencePlot(model1)
vif(model1)
avPlots(model1)
model2 = lm(Price ~ Food + Decor + Location, data = restaurants)
summary(model2)
plot(model2)
AIC(model.saturated, model1, model2, model.service)
#BIC
BIC(model.saturated, model1, model2, model.service)
setwd("~/Data_Science/NYC_Bootcamp")
credit = read.csv("./data/credit.csv")
credit = read.csv("credit.csv")
View(credit)
set.seed(0)
index = sample(1:nrow(credit), size= nrow(credit)*0.7)
### Training
logit = glm(default~., data = credit[index, ], family = 'binomial')
### Testing
prob = predict(logit, credit[-index, ], type="response")
mean((prob>=0.5) == (credit$default[-index]=='yes'))
y = c(rep('a', 9990), rep('b', 10))
set.seed(2)
index = sample(1:10000, size= 7000)
label_train = y[index]
label_test = y[-index]
print(mean(label_train=='b'))
print(mean(label_test=='b'))
library(caret)
folds = createFolds(credit$default, 5)
str(folds)
folds = createFolds(y,5)
str(folds)
y = c(rep('a', 9990), rep('b', 10))
folds = createFolds(y,5)
str(folds)
setwd("C:/Users/Stephen/Desktop/ML_Proj")
test = read.csv("test.csv")
head(test)
library(MASS)
head(test)
step = stepAIC(test,direction="both")
?stepAIC
test_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood, data = test, na.action = na.omit)
train = read.csv("training.csv")
train = read.csv("train.csv")
library(MASS)
head(test)
head(train)
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + Utilities, data = train, na.action = na.omit)
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd
+ HalfBath + FullBath, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd
+ HalfBath + FullBath, +
MasVnrType + MasVnrArea + ExterQual, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd
+ HalfBath + FullBath, +
MasVnrType + MasVnrArea + ExterQual, data = train, na.action = na.omit)
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd
+ HalfBath + FullBath, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + FireplaceQu + YearRemodAdd
+ HalfBath + FullBath +
CentralAir, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + YearRemodAdd + HalfBath + FullBath +
CentralAir, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + YearRemodAdd + HalfBath + FullBath +
CentralAir + Electrical, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
step = stepAIC(train_full,direction="both")
train_full = lm(SalePrice ~ LotArea + LotFrontage + LotShape + LandContour + YearBuilt +
Neighborhood + YearRemodAdd + HalfBath + FullBath +
CentralAir + KitchenQual, data = train, na.action = na.omit)
step = stepAIC(train_full,direction="both")
step
model1 = lm(Price ~ Food + Decor, data = restaurants)
summary(model1)
plot(model1)
influencePlot(model1)
influencePlot(model1)
plot(model1)
avPlots(model1)
vif(model1)
model2 = lm(Price ~ Food + Decor + Location, data = restaurants)
summary(model2)
plot(model2)
influencePlot(model2)
vif(model2)
avPlots(model2)
library(ggplot2)
head(restaurants)
plot(restaurants[, -c(1, 6)], col = restaurants$Location)
ggpairs(restaurants[,2:6], aes(color = Location))
vif(model1)
model2 = lm(Price ~ Food + Decor + Location, data = restaurants)
vif(model2)
AIC(model.saturated, model1, model2, model.service)
#BIC
BIC(model.saturated, model1, model2, model.service)
